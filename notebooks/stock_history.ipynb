{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "535fbb07-6fef-4972-80ed-3bd82c0b374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re  # Add this line at the beginning of your code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf906b76-45d2-4d57-9835-e2177f224838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Date format conversion failed with specified format. Trying 'mixed' format...\n",
      "Successfully parsed dates using 'mixed' format.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Cleans text by performing lowercasing, removing punctuation, and removing stop words.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to be cleaned.\n",
    "\n",
    "  Returns:\n",
    "      str: The cleaned text.\n",
    "  \"\"\"\n",
    "  text = text.lower()  # Lowercase\n",
    "  text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "  stop_words = stopwords.words('english')\n",
    "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "  return text\n",
    "\n",
    "\n",
    "\n",
    "def load_and_clean_data(data_file):\n",
    "  \"\"\"\n",
    "  Loads financial data from a CSV file, performs cleaning steps, and performs sentiment analysis on headlines.\n",
    "\n",
    "  Args:\n",
    "      data_file (str): Path to the CSV file containing financial data.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: Cleaned DataFrame containing financial data with sentiment analysis results.\n",
    "  \"\"\"\n",
    "\n",
    "  data = pd.read_csv(data_file)\n",
    "\n",
    "  # Handle missing values\n",
    "  data.dropna(subset=['stock', 'date'], inplace=True)\n",
    "\n",
    "  # Handle duplicates (keep only the most recent per stock)\n",
    "  data.sort_values(by=['date'], ascending=False, inplace=True)  # Sort by date (descending)\n",
    "  data.drop_duplicates(subset='stock', keep='last', inplace=True)\n",
    "\n",
    "  # Attempt date conversion\n",
    "  try:\n",
    "    # Adjust format if needed (e.g., '%Y-%m-%d %H:%M:%S')\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "  except ValueError:\n",
    "    print(\"Error: Date format conversion failed with specified format. Trying 'mixed' format...\")\n",
    "    try:\n",
    "      data['date'] = pd.to_datetime(data['date'], errors='coerce', format='mixed')\n",
    "      print(\"Successfully parsed dates using 'mixed' format.\")\n",
    "    except:\n",
    "      print(\"Failed to convert all dates. Daily frequency analysis might be inaccurate.\")\n",
    "\n",
    "  return data\n",
    "\n",
    "# Load and clean data\n",
    "data = load_and_clean_data(\"../data/raw_analyst_ratings.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0e0b52a-c7b7-4f9d-bc27-5564d406402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_range(group):\n",
    "  start = group[\"date\"].min()\n",
    "  if pd.isna(start):\n",
    "    start = 'NA'  # Or any default value\n",
    "  else:\n",
    "    start = start.strftime('%Y-%m-%d')\n",
    "  end = group[\"date\"].max()\n",
    "  if pd.isna(end):\n",
    "    end = 'NA'\n",
    "  else:\n",
    "    end = end.strftime('%Y-%m-%d')\n",
    "  return start, end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01bfee0a-b8a2-4310-a9fe-d1e83053baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_prices(data, date_ranges, output_file=\"stock_prices.csv\"):\n",
    "  \"\"\"\n",
    "  Downloads historical stock prices and appends them to a CSV file.\n",
    "\n",
    "  Args:\n",
    "      data: pandas DataFrame containing stock symbols and dates.\n",
    "      date_ranges: pandas DataFrame containing start and end dates for each stock.\n",
    "      output_file: Path to the output CSV file (default: \"stock_prices.csv\").\n",
    "  \"\"\"\n",
    "\n",
    "  with open(output_file, \"a\") as f:  # Open file in append mode\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Check if file is empty (optional)\n",
    "    # if f.tell() == 0:\n",
    "    #   writer.writerow([\"Symbol\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"])\n",
    "\n",
    "    for symbol, (start, end) in date_ranges.iterrows():\n",
    "      try:\n",
    "        # Download stock data using yfinance\n",
    "        stock_data = yf.download(symbol, start=start, end=end)\n",
    "\n",
    "        # Print downloaded data (for debugging)\n",
    "        # print(stock_data)\n",
    "\n",
    "        # Convert downloaded data to a DataFrame (assuming daily data)\n",
    "        stock_data_df = stock_data[[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]]\n",
    "        stock_data_df.reset_index(inplace=True)  # Add 'Date' column as index\n",
    "        stock_data_df[\"Symbol\"] = symbol  # Add 'Symbol' column\n",
    "\n",
    "        # Print DataFrame contents (for debugging)\n",
    "        # print(stock_data_df)\n",
    "\n",
    "        # Append data to CSV in chunks for large datasets (optional)\n",
    "        for i in range(0, len(stock_data_df), 1000):\n",
    "          writer.writerows(stock_data_df.iloc[i:i+1000].values.tolist())\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Error downloading data for {symbol}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b0b8dd3-14a7-401c-b804-5bf0fbd79ced",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming your downloaded data is stored in \"stock_prices.csv\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stock_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_prices.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Python_Lab\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\Python_Lab\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Python_Lab\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\Python_Lab\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Python_Lab\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:586\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# Assuming your downloaded data is stored in \"stock_prices.csv\"\n",
    "stock_data = pd.read_csv(\"stock_prices.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21526be5-5138-47aa-9a03-d9ddcf692b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific stock symbol and date range for plotting\n",
    "symbol = \"AAPL\"  # Replace with your desired symbol\n",
    "start_date = \"2023-01-01\"  # Replace with your desired start date\n",
    "end_date = \"2024-05-04\"  # Replace with your desired end date\n",
    "\n",
    "stock_data_filtered = stock_data[(stock_data[\"Symbol\"] == symbol) & \n",
    "                                 (stock_data[\"Date\"] >= start_date) & \n",
    "                                 (stock_data[\"Date\"] <= end_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a274709-ffb4-4658-943a-24a54aa9559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "plt.plot(stock_data_filtered[\"Date\"], stock_data_filtered[\"Close\"], label=\"Closing Price\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Closing Price\")\n",
    "plt.title(f\"Closing Price of {symbol} ({start_date} - {end_date})\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Optional: Customize plot (e.g., markers, colors)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
